{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXu7g3XJybq7",
        "outputId": "1a313683-3bed-4d00-b8cc-623ae3977b5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset prepared and saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'usecase_4_.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Handle Missing Values\n",
        "data['Collaborators'] = data['Collaborators'].fillna('None')\n",
        "data['Results First Posted'] = data['Results First Posted'].fillna('Missing')\n",
        "\n",
        "# Handle Categorical Columns\n",
        "# Encode Study Status\n",
        "data = pd.get_dummies(data, columns=['Study Status', 'Sex', 'Funder Type'], drop_first=True)\n",
        "\n",
        "# Process | Separated Columns\n",
        "def count_items(column):\n",
        "    return column.fillna('').apply(lambda x: len(str(x).split('|')))\n",
        "\n",
        "data['Conditions Count'] = count_items(data['Conditions'])\n",
        "data['Interventions Count'] = count_items(data['Interventions'])\n",
        "data['Locations Count'] = count_items(data['Locations'])\n",
        "data['Phases Count'] = count_items(data['Phases'])\n",
        "\n",
        "# One-hot encode keywords in Conditions, Interventions, etc.\n",
        "data['Has DRUG Intervention'] = data['Interventions'].str.contains('DRUG', na=False).astype(int)\n",
        "\n",
        "# Extract Features from Study Design\n",
        "def extract_design_features(design):\n",
        "    features = {'Allocation': '', 'Intervention Model': '', 'Masking': '', 'Primary Purpose': ''}\n",
        "    if pd.notnull(design):\n",
        "        for part in design.split('|'):\n",
        "            key, val = part.split(': ', 1)\n",
        "            features[key] = val.strip()\n",
        "    return pd.Series(features)\n",
        "\n",
        "design_features = data['Study Design'].apply(extract_design_features)\n",
        "data = pd.concat([data, design_features], axis=1).drop(columns=['Study Design'])\n",
        "\n",
        "# Convert Dates\n",
        "date_columns = ['Start Date', 'Primary Completion Date', 'Completion Date']\n",
        "for col in date_columns:\n",
        "    data[col] = pd.to_datetime(data[col], errors='coerce')\n",
        "\n",
        "# Create Derived Date Features\n",
        "data['Study Duration (Days)'] = (data['Completion Date'] - data['Start Date']).dt.days\n",
        "data['Start Year'] = data['Start Date'].dt.year\n",
        "data['Completion Year'] = data['Completion Date'].dt.year\n",
        "\n",
        "# Drop unnecessary columns\n",
        "columns_to_drop = ['Study Title', 'Study URL', 'Brief Summary', 'Other Outcome Measures', 'Locations']\n",
        "data = data.drop(columns=columns_to_drop)\n",
        "\n",
        "# Ensure Target Column is Numeric\n",
        "data['Study Recruitment Rate'] = pd.to_numeric(data['Study Recruitment Rate'], errors='coerce')\n",
        "\n",
        "# Handle Remaining Missing Values\n",
        "data = data.fillna(0)\n",
        "\n",
        "# Save the cleaned dataset\n",
        "data.to_csv('cleaned_clinical_trials.csv', index=False)\n",
        "\n",
        "print(\"Dataset prepared and saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'usecase_4_.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Handle Missing Values\n",
        "data['Collaborators'] = data['Collaborators'].fillna('None')\n",
        "data['Results First Posted'] = data['Results First Posted'].fillna('Missing')\n",
        "\n",
        "# Handle Categorical Columns\n",
        "# Encode Study Status, Sex, and Funder Type\n",
        "data = pd.get_dummies(data, columns=['Study Status', 'Sex', 'Funder Type'], drop_first=True)\n",
        "\n",
        "# Process | Separated Columns\n",
        "def count_items(column):\n",
        "    return column.fillna('').apply(lambda x: len(str(x).split('|')))\n",
        "\n",
        "data['Conditions Count'] = count_items(data['Conditions'])\n",
        "data['Interventions Count'] = count_items(data['Interventions'])\n",
        "data['Locations Count'] = count_items(data['Locations'])\n",
        "data['Phases Count'] = count_items(data['Phases'])\n",
        "\n",
        "# Frequency Encoding for Conditions\n",
        "condition_list = data['Conditions'].dropna().str.split('|').explode()\n",
        "condition_freq = Counter(condition_list)\n",
        "\n",
        "def average_condition_freq(conditions):\n",
        "    return np.mean([condition_freq.get(cond, 0) for cond in conditions.split('|')])\n",
        "\n",
        "data['Avg Condition Frequency'] = data['Conditions'].fillna('').apply(average_condition_freq)\n",
        "\n",
        "# Frequency Encoding for Interventions\n",
        "intervention_list = data['Interventions'].dropna().str.split('|').explode()\n",
        "intervention_freq = Counter(intervention_list)\n",
        "\n",
        "def average_intervention_freq(interventions):\n",
        "    return np.mean([intervention_freq.get(interv, 0) for interv in interventions.split('|')])\n",
        "\n",
        "data['Avg Intervention Frequency'] = data['Interventions'].fillna('').apply(average_intervention_freq)\n",
        "\n",
        "# Count Specific Intervention Types (e.g., DRUG)\n",
        "data['Drug Intervention Count'] = data['Interventions'].fillna('').apply(\n",
        "    lambda x: sum(1 for i in x.split('|') if i.startswith('DRUG'))\n",
        ")\n",
        "\n",
        "# Extract Features from Study Design\n",
        "def extract_design_features(design):\n",
        "    features = {'Allocation': '', 'Intervention Model': '', 'Masking': '', 'Primary Purpose': ''}\n",
        "    if pd.notnull(design):\n",
        "        for part in design.split('|'):\n",
        "            key, val = part.split(': ', 1)\n",
        "            features[key] = val.strip()\n",
        "    return pd.Series(features)\n",
        "\n",
        "design_features = data['Study Design'].apply(extract_design_features)\n",
        "data = pd.concat([data, design_features], axis=1).drop(columns=['Study Design'])\n",
        "\n",
        "# Convert Dates\n",
        "date_columns = ['Start Date', 'Primary Completion Date', 'Completion Date']\n",
        "for col in date_columns:\n",
        "    data[col] = pd.to_datetime(data[col], errors='coerce')\n",
        "\n",
        "# Create Derived Date Features\n",
        "data['Study Duration (Days)'] = (data['Completion Date'] - data['Start Date']).dt.days\n",
        "data['Start Year'] = data['Start Date'].dt.year\n",
        "data['Completion Year'] = data['Completion Date'].dt.year\n",
        "\n",
        "# Drop unnecessary columns\n",
        "columns_to_drop = ['Study Title', 'Study URL', 'Brief Summary', 'Other Outcome Measures', 'Locations']\n",
        "data = data.drop(columns=columns_to_drop)\n",
        "\n",
        "# Ensure Target Column is Numeric\n",
        "data['Study Recruitment Rate'] = pd.to_numeric(data['Study Recruitment Rate'], errors='coerce')\n",
        "\n",
        "# Handle Remaining Missing Values\n",
        "data = data.fillna(0)\n",
        "\n",
        "# Save the cleaned dataset\n",
        "data.to_csv('Final_Nest_cleaned_clinical_trials.csv', index=False)\n",
        "\n",
        "print(\"Dataset prepared and saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teXARI0D5L1s",
        "outputId": "d6835818-3738-4823-f10a-107e01b2913f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset prepared and saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'usecase_4_.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Handle Missing Values\n",
        "data['Collaborators'] = data['Collaborators'].fillna('None')\n",
        "data['Results First Posted'] = data['Results First Posted'].fillna('Missing')\n",
        "\n",
        "# Handle Categorical Columns\n",
        "# Encode Study Status, Sex, and Funder Type\n",
        "data = pd.get_dummies(data, columns=['Study Status', 'Sex', 'Funder Type'], drop_first=True)\n",
        "\n",
        "# Process | Separated Columns\n",
        "def count_items(column):\n",
        "    return column.fillna('').apply(lambda x: len(str(x).split('|')))\n",
        "\n",
        "data['Conditions Count'] = count_items(data['Conditions'])\n",
        "data['Interventions Count'] = count_items(data['Interventions'])\n",
        "data['Locations Count'] = count_items(data['Locations'])\n",
        "data['Phases Count'] = count_items(data['Phases'])\n",
        "\n",
        "# Frequency Encoding for Conditions\n",
        "condition_list = data['Conditions'].dropna().str.split('|').explode()\n",
        "condition_freq = Counter(condition_list)\n",
        "\n",
        "def average_condition_freq(conditions):\n",
        "    if pd.isna(conditions) or conditions == '':\n",
        "        return 0\n",
        "    return np.mean([condition_freq.get(cond.strip(), 0) for cond in conditions.split('|')])\n",
        "\n",
        "data['Avg Condition Frequency'] = data['Conditions'].fillna('').apply(average_condition_freq)\n",
        "\n",
        "# Frequency Encoding for Interventions\n",
        "intervention_list = data['Interventions'].dropna().str.split('|').explode()\n",
        "intervention_freq = Counter(intervention_list)\n",
        "\n",
        "def average_intervention_freq(interventions):\n",
        "    if pd.isna(interventions) or interventions == '':\n",
        "        return 0\n",
        "    return np.mean([intervention_freq.get(interv.strip(), 0) for interv in interventions.split('|')])\n",
        "\n",
        "data['Avg Intervention Frequency'] = data['Interventions'].fillna('').apply(average_intervention_freq)\n",
        "\n",
        "# Count Specific Intervention Types (e.g., DRUG)\n",
        "data['Drug Intervention Count'] = data['Interventions'].fillna('').apply(\n",
        "    lambda x: sum(1 for i in x.split('|') if i.startswith('DRUG'))\n",
        ")\n",
        "\n",
        "# Extract Features from Study Design\n",
        "def extract_design_features(design):\n",
        "    features = {'Allocation': '', 'Intervention Model': '', 'Masking': '', 'Primary Purpose': ''}\n",
        "    if pd.notnull(design):\n",
        "        for part in design.split('|'):\n",
        "            key, val = part.split(': ', 1)\n",
        "            features[key] = val.strip()\n",
        "    return pd.Series(features)\n",
        "\n",
        "design_features = data['Study Design'].apply(extract_design_features)\n",
        "data = pd.concat([data, design_features], axis=1).drop(columns=['Study Design'])\n",
        "\n",
        "# Convert Dates\n",
        "date_columns = ['Start Date', 'Primary Completion Date', 'Completion Date']\n",
        "for col in date_columns:\n",
        "    data[col] = pd.to_datetime(data[col], errors='coerce')\n",
        "\n",
        "# Create Derived Date Features\n",
        "data['Study Duration (Days)'] = (data['Completion Date'] - data['Start Date']).dt.days\n",
        "data['Start Year'] = data['Start Date'].dt.year\n",
        "data['Completion Year'] = data['Completion Date'].dt.year\n",
        "\n",
        "# Drop unnecessary columns\n",
        "columns_to_drop = ['Study Title', 'Study URL', 'Brief Summary', 'Other Outcome Measures', 'Locations']\n",
        "data = data.drop(columns=columns_to_drop)\n",
        "\n",
        "# Ensure Target Column is Numeric\n",
        "data['Study Recruitment Rate'] = pd.to_numeric(data['Study Recruitment Rate'], errors='coerce')\n",
        "\n",
        "# Handle Remaining Missing Values\n",
        "data = data.fillna(0)\n",
        "\n",
        "# Save the cleaned dataset\n",
        "data.to_csv('PS4_cleaned_clinical_trials.csv', index=False)\n",
        "\n",
        "print(\"Dataset prepared and saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGLwmPb4_nUa",
        "outputId": "5f44768c-72aa-4406-f9ff-e5cafc00e86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset prepared and saved successfully!\n"
          ]
        }
      ]
    }
  ]
}